{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of deep learning and neural networks\n",
    "\n",
    "In this notebook, we will become familiar with the fundamental concepts used in deep learning. We will build simple neural networks and generate predictions with them.\n",
    "\n",
    "We will be working with networks in order to predict transactions for a bank.\n",
    "\n",
    "Overview:\n",
    "1. Basics of deep learning and neural networks\n",
    "1. The Rectified Linear Activation Function (ReLU)\n",
    "1. Applying the network to many observations/rows of data\n",
    "1. Deeper networks\n",
    "    1. Calculating the error for one data point\n",
    "    1. Scaling up to multiple data points\n",
    "1. The need for optimization\n",
    "1. Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Basics of deep learning and neural networks\n",
    "\n",
    "We will code a **forward propagation** (prediction) for our first neural network.\n",
    "\n",
    "Say that each data point is a customer. The first input is how many accounts they have, and the second input is how many children they have. The model will predict **how many transactions the user makes in the next year**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-39"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hard-code input data and weights\n",
    "num_accounts: int = 3\n",
    "num_children: int = 5\n",
    "\n",
    "input_data: np.ndarray = np.array([num_accounts, num_children])\n",
    "    \n",
    "weights: Dict[str, np.ndarray] = {'node_0': np.array([2, 4]), \n",
    "                                  'node_1': np.array([ 4, -5]), \n",
    "                                  'output': np.array([2, 7])}\n",
    "\n",
    "# Calculate the nodes and the output of the neural network\n",
    "node_0_value: np.int32 = (input_data * weights['node_0']).sum()\n",
    "\n",
    "node_1_value: np.int32 = (input_data * weights['node_1']).sum()\n",
    "\n",
    "hidden_layer_outputs: np.ndarray = np.array([node_0_value, node_1_value])\n",
    "\n",
    "output: np.int32 = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the network generated a prediction of $-39$ transactions. This number does not make sense as we have to add an activation function as in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. The Rectified Linear Activation Function\n",
    "\n",
    "An \"activation function\" is a function applied at each node. It converts the node's input into some output.\n",
    "\n",
    "The rectified linear activation function (called **ReLU**) has been shown to lead to very high-performance networks. This function takes a single number as an input, returning 0 if the input is negative, and the input if the input is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(input: np.int32) -> int:\n",
    "    '''ReLU activation function.'''\n",
    "    return max(input, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_0_input: np.int32 = (input_data * weights['node_0']).sum()\n",
    "node_0_output: int = relu(node_0_input)\n",
    "\n",
    "node_1_input: np.int32 = (input_data * weights['node_1']).sum()\n",
    "node_1_output: int = relu(node_1_input)\n",
    "\n",
    "hidden_layer_outputs: np.ndarray = np.array([node_0_output, node_1_output])\n",
    "\n",
    "model_output: np.int32 = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predicted $52$ transactions. Without this activation function, you would have predicted a negative number ($-39$)! The real power of activation functions will come soon when we start tuning model weights.\n",
    "\n",
    "## Section 3. Applying the network to many observations/rows of data\n",
    "\n",
    "You'll now define a function called `predict_with_network()` which will generate predictions for multiple data observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_network(input_data_row, weights):\n",
    "\n",
    "    node_0_input = (input_data_row * weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    node_1_input = (input_data_row * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    hidden_layer_outputs: np.ndarray = np.array([node_0_output, node_1_output])\n",
    "\n",
    "    input_to_final_layer = (hidden_layer_outputs * weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data: List[np.ndarray] = [np.array([3, 5]),\n",
    "                                np.array([ 1, -1]),\n",
    "                                np.array([0, 0]),\n",
    "                                np.array([8, 4])]\n",
    "\n",
    "weights: Dict[str, np.ndarray] = {'node_0': np.array([2, 4]),\n",
    "                                  'node_1': np.array([ 4, -5]),\n",
    "                                  'output': np.array([2, 7])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52, 63, 0, 148]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results: List[np.int32] = []\n",
    "for input_data_row in input_data:\n",
    "    results.append(predict_with_network(input_data_row, weights))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have predicted the number of transactions for 4 observations (i.e. individuals)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Deeper networks\n",
    "\n",
    "An important fact about deep networks is that they internally build up representations of the patterns in the data that are useful for making predictions. And they find increasingly complex patterns as we go through successive hidden layers of the network.\n",
    "\n",
    "Deep learning is also sometimes called **representation learning**, because subsequent layers build increasingly sophiscticated representations of the raw data, until we get to a stage where we can make preditions. In other words, the last layers capture the most complex interactions.\n",
    "\n",
    "The cool thing about DL is that we do not need to specify the interactions. Instead, the network gets weights that find the relevant patterns to make better predictions. It is the model training process sets them to optimize predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_network(input_data: np.ndarray, weights):\n",
    "    \"\"\"Predicts the number of transactions using a deep network.\"\"\"\n",
    "    # Calculate node 0 in the first hidden layer\n",
    "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "\n",
    "    # Calculate node 1 in the first hidden layer\n",
    "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "\n",
    "    # Put node values into a numpy array\n",
    "    hidden_0_outputs: np.ndarray = np.array([node_0_0_output, node_0_1_output])\n",
    "    \n",
    "    # Calculate node 0 in the second hidden layer\n",
    "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
    "    node_1_0_output = relu(node_1_0_input)\n",
    "\n",
    "    # Calculate node 1 in the second hidden layer\n",
    "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
    "    node_1_1_output = relu(node_1_1_input)\n",
    "\n",
    "    # Put node values into a numpy array\n",
    "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
    "\n",
    "    # Calculate model output\n",
    "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
    "    \n",
    "    return(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "input_data: np.ndarray = np.array([3, 5])\n",
    "\n",
    "weights: Dict[str, np.ndarray] = {'node_0_0': np.array([2, 4]),\n",
    "                                  'node_0_1': np.array([ 4, -5]),\n",
    "                                  'node_1_0': np.array([-1,  2]),\n",
    "                                  'node_1_1': np.array([1, 2]),\n",
    "                                  'output': np.array([2, 7])}\n",
    "    \n",
    "output = predict_with_network(input_data, weights)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network generated a prediction of 182 transactions.\n",
    "\n",
    "## Section 5. The need for optimization\n",
    "\n",
    "### Subsection 5.1 Calculating the error for one data point\n",
    "\n",
    "We will now see how we can improve the model accuracy by changing values of weights. For the moment, we won't use an activation function in this example. Or, we can supose that we are using an activation function that returns the input. We call such a function the identity function.\n",
    "\n",
    "Let's say that the **true value of the target** is 3. So, the closer our prediction is to 3, the more accurate the model is for this data point.\n",
    "\n",
    "We will use **forward propagation** to fill in the values of the hidden layer.\n",
    "\n",
    "The **error** can be computes as follows: $$ \\text{Error} = \\text{Predicted target value} - \\text{Actual target value}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_network(input_data_point: np.ndarray, weights: Dict[str, List[int]]) -> np.float64:\n",
    "    node_0_input = (input_data_point * weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    node_1_input = (input_data_point * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    hidden_layer_values = np.array([node_0_output, node_1_output])\n",
    "    input_to_final_layer = (hidden_layer_values * weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "    \n",
    "    return(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "input_data: np.ndarray = np.array([0, 3])\n",
    "\n",
    "# Sample weights\n",
    "weights_0: Dict[str, List[int]] = {'node_0': [2, 1],\n",
    "                                   'node_1': [1, 2],\n",
    "                                   'output': [1, 1]}\n",
    "\n",
    "# The actual target value, use to calculate the error\n",
    "target_actual: int = 3\n",
    "\n",
    "# Make prediction using original weights\n",
    "model_output_0: List[np.float64] = predict_with_network(input_data, weights_0)\n",
    "\n",
    "# Calculate error\n",
    "error_0 = model_output_0 - target_actual\n",
    "\n",
    "# Create weights that cause the network to make perfect prediction (3)\n",
    "weights_1 = {'node_0': [2, 1],\n",
    "             'node_1': [1, 0],\n",
    "             'output': [1, 1]}\n",
    "\n",
    "# Make prediction using new weights\n",
    "model_output_1: List[np.float64] = predict_with_network(input_data, weights_1)\n",
    "\n",
    "# Calculate the new error\n",
    "error_1: np.int32 = model_output_1 - target_actual\n",
    "\n",
    "print(error_0)\n",
    "print(error_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 5.2 Scaling up to multiple data points\n",
    "\n",
    "We've seen how different weights will have different accuracies on a single prediction. But usually, we'll want to measure model accuracy on many points. \n",
    "\n",
    "We'll compare model accuracies for two different sets of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_0: Dict[str, np.ndarray] = {'node_0': np.array([2, 1]), \n",
    "                                    'node_1': np.array([1, 2]), \n",
    "                                    'output': np.array([1, 1])}\n",
    "\n",
    "weights_1: Dict[str, np.ndarray] = {'node_0': np.array([2, 1]),\n",
    "                                    'node_1': np.array([1. , 1.5]),\n",
    "                                    'output': np.array([1. , 1.5])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`input_data` is a list of arrays. Each item in that list contains the data to make a single prediction. \n",
    "\n",
    "`target_actuals` is a list of numbers. Each item in that list is the actual value we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data: List[np.ndarray] = [np.array([0, 3]), \n",
    "                                np.array([1, 2]), \n",
    "                                np.array([-1, -2]), \n",
    "                                np.array([4, 0])]\n",
    "\n",
    "target_actuals: List[int] =  [1, 3, 5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `mean_squared_error()` function from `sklearn.metrics`. It takes the true values and the predicted values as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error with weights_0: 37.50\n",
      "Mean squared error with weights_1: 49.89\n"
     ]
    }
   ],
   "source": [
    "model_output_0: List[np.int32] = []\n",
    "model_output_1: List[np.int32] = []\n",
    "\n",
    "for row in input_data:\n",
    "    model_output_0.append(predict_with_network(row, weights_0))\n",
    "    model_output_1.append(predict_with_network(row, weights_1))\n",
    "\n",
    "mse_0: float = mean_squared_error(target_actuals, model_output_0)\n",
    "mse_1: float = mean_squared_error(target_actuals, model_output_1)\n",
    "\n",
    "print(f\"Mean squared error with weights_0: {mse_0:.2f}\")\n",
    "print(f\"Mean squared error with weights_1: {mse_1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like `model_output_1` has a higher mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6. Gradient descent\n",
    "\n",
    "With gradient descent we repeatedly find a slope capturing how our loss function, $\\text{Loss}(\\omega)$, changes as a weight changes. We then do a small change to the weight to get to a lower point, and we repeat this process until we couldn't go downhill anymore.\n",
    "\n",
    "If the slope is positive, going opposite to the slope means moving to lower numbers. How do we achieve this? Subtracting the slope from the current value. But a too big step might lead us astray. Thus, instead of directly subtracting the slope, we multiply the slope by a small number, called the **learning rate**, and we update the weight by the product of that multiplication: $$ \\text{Updated weights} = \\text{weights} - \\text{slope} \\times \\text{learning rate}. $$\n",
    "\n",
    "We typically use a learning rate of $0.01$. This ensures that we take small steps, such that we reliably move towards the optimal weights.\n",
    "\n",
    "How do we find the relevant slope for each weight we need to update? Remember the chain rule of calculus... To calculate the slope for a weight, we need to multiply:\n",
    "1. The slope of the loss function wrt the value at the node we feed\n",
    "1. The value of the node that feeds into our weight\n",
    "1. The slope of the activation function wrt the value we feed into\n",
    "\n",
    "Let's put away the last point for a moment. The slope of the Mean-Squared loss function wrt to the prediction can be written as follows: $$2\\times\\text{Error}$$ where $\\text{error} = \\text{Predicted value} - \\text{Actual value}$ as aforementioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(input_data: np.ndarray, target: int, weights: np.ndarray) -> np.int32:\n",
    "    preds: np.int32 = (weights * input_data).sum()\n",
    "    error: np.int32 = preds - target\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(input_data: np.ndarray, target: int, weights: np.ndarray) -> np.ndarray:\n",
    "    error: np.int32 = get_error(input_data, target, weights)\n",
    "    slope: np.ndarray = 2 * input_data * error\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(input_data: np.ndarray, target: int, weights: np.ndarray) -> np.float64:\n",
    "    errors: np.int32 = get_error(input_data, target, weights)\n",
    "    mse: np.float64 = np.mean(errors**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data: np.ndarray = np.array([1, 2, 3])\n",
    "target: int = 0\n",
    "weights: np.ndarray = np.array([0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.75060288e-05 5.50120575e-05 8.25180863e-05]\n",
      "[-0.49999929  1.00000141 -0.49999788]\n",
      "[1.98043407e-05 3.96086814e-05 5.94130221e-05]\n",
      "[-0.49999949  1.00000102 -0.49999847]\n",
      "[1.42591253e-05 2.85182506e-05 4.27773759e-05]\n",
      "[-0.49999963  1.00000073 -0.4999989 ]\n",
      "[1.02665702e-05 2.05331405e-05 3.07997107e-05]\n",
      "[-0.49999974  1.00000053 -0.49999921]\n",
      "[7.39193056e-06 1.47838611e-05 2.21757917e-05]\n",
      "[-0.49999981  1.00000038 -0.49999943]\n",
      "[5.32219001e-06 1.06443800e-05 1.59665700e-05]\n",
      "[-0.49999986  1.00000027 -0.49999959]\n",
      "[3.83197680e-06 7.66395361e-06 1.14959304e-05]\n",
      "[-0.4999999  1.0000002 -0.4999997]\n",
      "[2.7590233e-06 5.5180466e-06 8.2770699e-06]\n",
      "[-0.49999993  1.00000014 -0.49999979]\n",
      "[1.98649678e-06 3.97299355e-06 5.95949033e-06]\n",
      "[-0.49999995  1.0000001  -0.49999985]\n",
      "[1.43027768e-06 2.86055536e-06 4.29083303e-06]\n",
      "[-0.49999996  1.00000007 -0.49999989]\n",
      "[1.02979993e-06 2.05959986e-06 3.08939979e-06]\n",
      "[-0.49999997  1.00000005 -0.49999992]\n",
      "[7.41455949e-07 1.48291190e-06 2.22436785e-06]\n",
      "[-0.49999998  1.00000004 -0.49999994]\n",
      "[5.33848283e-07 1.06769657e-06 1.60154485e-06]\n",
      "[-0.49999999  1.00000003 -0.49999996]\n",
      "[3.84370764e-07 7.68741527e-07 1.15311229e-06]\n",
      "[-0.49999999  1.00000002 -0.49999997]\n",
      "[2.76746949e-07 5.53493899e-07 8.30240848e-07]\n",
      "[-0.49999999  1.00000001 -0.49999998]\n",
      "[1.99257804e-07 3.98515608e-07 5.97773412e-07]\n",
      "[-0.49999999  1.00000001 -0.49999998]\n",
      "[1.43465619e-07 2.86931238e-07 4.30396857e-07]\n",
      "[-0.5         1.00000001 -0.49999999]\n",
      "[1.03295246e-07 2.06590491e-07 3.09885737e-07]\n",
      "[-0.5         1.00000001 -0.49999999]\n",
      "[7.43725765e-08 1.48745153e-07 2.23117730e-07]\n",
      "[-0.5         1.         -0.49999999]\n",
      "[5.35482552e-08 1.07096510e-07 1.60644765e-07]\n",
      "[-0.5  1.  -0.5]\n"
     ]
    }
   ],
   "source": [
    "n_updates: int = 20\n",
    "learning_rate: float = 0.01\n",
    "mse_hist: List[np.float64] = []\n",
    "\n",
    "# Iterate over the number of updates\n",
    "for i in range(n_updates):\n",
    "    # Calculate the slope\n",
    "    slope: np.ndarray = get_slope(input_data, target, weights)\n",
    "\n",
    "    # Update the weights\n",
    "    weights: np.ndarray = weights - slope * learning_rate\n",
    "\n",
    "    # Calculate MSE with new weights\n",
    "    mse: np.float64 = get_mse(input_data, target, weights)\n",
    "    mse_hist.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_hist, c='b', lw=1)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.grid(True, c='k', ls=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we can see, the mean-squared error decreases as the number of iterations goes up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
