{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of deep learning and neural networks\n",
    "\n",
    "In this notebook, we will become familiar with the fundamental concepts used in deep learning. We will build simple neural networks and generate predictions with them.\n",
    "\n",
    "We will be working with networks in order to predict transactions for a bank.\n",
    "\n",
    "Overview:\n",
    "1. [Basics of deep learning and neural networks](#Section-1.-Basics-of-deep-learning-and-neural-networks)\n",
    "1. [The Rectified Linear Activation Function (ReLU)](#Section-2.-The-Rectified-Linear-Activation-Function)\n",
    "1. [Applying the network to many observations/rows of data](#Section-3.-Applying-the-network-to-many-observations/rows-of-data)\n",
    "1. [Deeper networks](#Section-4.-Deeper-networks)\n",
    "1. [The need for optimization](#Section-5.-The-need-for-optimization)\n",
    "    1. [Calculating the error for one data point](#Subsection-5.1-Calculating-the-error-for-one-data-point)\n",
    "    1. [Scaling up to multiple data points](#Subsection-5.2-Scaling-up-to-multiple-data-points)\n",
    "1. [Gradient descent](#Section-6.-Gradient-descent)\n",
    "1. [Creating a keras model](#Section-7:-Creating-a-keras-model)\n",
    "    1. [EDA](#Subsection-7.1:-EDA)\n",
    "    1. [Specifying our model](#Subsection-7.2:-Specifying-our-model)\n",
    "    1. [Compiling and fitting our model](#Subsection-7.3:-Compiling-and-fitting-our-model)\n",
    "1. [Classification models](#Section-8.-Classification-models)\n",
    "1. [Using models](#Section-9.-Using-models)\n",
    "1. [Model Validation](#Section-11.-Model-Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\YBant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\YBant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\YBant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\YBant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\YBant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\YBant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from keras.engine.sequential import Sequential\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.core.frame import Series, DataFrame\n",
    "import numpy as np\n",
    "from numpy.core import ndarray, int32, float64\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Union\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir: str = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normabspath(basedir: str, filename: str):\n",
    "    return os.path.normpath(os.path.join(basedir, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Basics of deep learning and neural networks\n",
    "\n",
    "We will code a **forward propagation** (prediction) for our first neural network.\n",
    "\n",
    "Say that each data point is a customer. The first input is how many accounts they have, and the second input is how many children they have. The model will predict **how many transactions the user makes in the next year**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-39"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hard-code input data and weights\n",
    "num_accounts: int = 3\n",
    "num_children: int = 5\n",
    "\n",
    "input_data: np.ndarray = np.array([num_accounts, num_children])\n",
    "    \n",
    "weights: Dict[str, np.ndarray] = {'node_0': np.array([2, 4]), \n",
    "                                  'node_1': np.array([ 4, -5]), \n",
    "                                  'output': np.array([2, 7])}\n",
    "\n",
    "# Calculate the nodes and the output of the neural network\n",
    "node_0_value: np.int32 = (input_data * weights['node_0']).sum()\n",
    "\n",
    "node_1_value: np.int32 = (input_data * weights['node_1']).sum()\n",
    "\n",
    "hidden_layer_outputs: np.ndarray = np.array([node_0_value, node_1_value])\n",
    "\n",
    "output: np.int32 = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the network generated a prediction of $-39$ transactions. This number does not make sense as we have to add an activation function as in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. The Rectified Linear Activation Function\n",
    "\n",
    "An \"activation function\" is a function applied at each node. It converts the node's input into some output.\n",
    "\n",
    "The rectified linear activation function (called **ReLU**) has been shown to lead to very high-performance networks. This function takes a single number as an input, returning 0 if the input is negative, and the input if the input is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(input: np.int32) -> int:\n",
    "    '''ReLU activation function.'''\n",
    "    return max(input, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_0_input: np.int32 = (input_data * weights['node_0']).sum()\n",
    "node_0_output: int = relu(node_0_input)\n",
    "\n",
    "node_1_input: np.int32 = (input_data * weights['node_1']).sum()\n",
    "node_1_output: int = relu(node_1_input)\n",
    "\n",
    "hidden_layer_outputs: np.ndarray = np.array([node_0_output, node_1_output])\n",
    "\n",
    "model_output: np.int32 = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predicted $52$ transactions. Without this activation function, you would have predicted a negative number ($-39$)! The real power of activation functions will come soon when we start tuning model weights.\n",
    "\n",
    "## Section 3. Applying the network to many observations/rows of data\n",
    "\n",
    "You'll now define a function called `predict_with_network()` which will generate predictions for multiple data observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_network(input_data_row, weights):\n",
    "\n",
    "    node_0_input = (input_data_row * weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    node_1_input = (input_data_row * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    hidden_layer_outputs: np.ndarray = np.array([node_0_output, node_1_output])\n",
    "\n",
    "    input_to_final_layer = (hidden_layer_outputs * weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data: List[np.ndarray] = [np.array([3, 5]),\n",
    "                                np.array([ 1, -1]),\n",
    "                                np.array([0, 0]),\n",
    "                                np.array([8, 4])]\n",
    "\n",
    "weights: Dict[str, np.ndarray] = {'node_0': np.array([2, 4]),\n",
    "                                  'node_1': np.array([ 4, -5]),\n",
    "                                  'output': np.array([2, 7])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52, 63, 0, 148]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results: List[np.int32] = []\n",
    "for input_data_row in input_data:\n",
    "    results.append(predict_with_network(input_data_row, weights))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have predicted the number of transactions for 4 observations (i.e. individuals)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Deeper networks\n",
    "\n",
    "An important fact about deep networks is that they internally build up representations of the patterns in the data that are useful for making predictions. And they find increasingly complex patterns as we go through successive hidden layers of the network.\n",
    "\n",
    "Deep learning is also sometimes called **representation learning**, because subsequent layers build increasingly sophiscticated representations of the raw data, until we get to a stage where we can make preditions. In other words, the last layers capture the most complex interactions.\n",
    "\n",
    "The cool thing about DL is that we do not need to specify the interactions. Instead, the network gets weights that find the relevant patterns to make better predictions. It is the model training process sets them to optimize predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_network(input_data: np.ndarray, weights):\n",
    "    \"\"\"Predicts the number of transactions using a deep network.\"\"\"\n",
    "    # Calculate node 0 in the first hidden layer\n",
    "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "\n",
    "    # Calculate node 1 in the first hidden layer\n",
    "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "\n",
    "    # Put node values into a numpy array\n",
    "    hidden_0_outputs: np.ndarray = np.array([node_0_0_output, node_0_1_output])\n",
    "    \n",
    "    # Calculate node 0 in the second hidden layer\n",
    "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
    "    node_1_0_output = relu(node_1_0_input)\n",
    "\n",
    "    # Calculate node 1 in the second hidden layer\n",
    "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
    "    node_1_1_output = relu(node_1_1_input)\n",
    "\n",
    "    # Put node values into a numpy array\n",
    "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
    "\n",
    "    # Calculate model output\n",
    "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
    "    \n",
    "    return(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "input_data: np.ndarray = np.array([3, 5])\n",
    "\n",
    "weights: Dict[str, np.ndarray] = {'node_0_0': np.array([2, 4]),\n",
    "                                  'node_0_1': np.array([ 4, -5]),\n",
    "                                  'node_1_0': np.array([-1,  2]),\n",
    "                                  'node_1_1': np.array([1, 2]),\n",
    "                                  'output': np.array([2, 7])}\n",
    "    \n",
    "output = predict_with_network(input_data, weights)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network generated a prediction of 182 transactions.\n",
    "\n",
    "## Section 5. The need for optimization\n",
    "\n",
    "### Subsection 5.1 Calculating the error for one data point\n",
    "\n",
    "We will now see how we can improve the model accuracy by changing values of weights. For the moment, we won't use an activation function in this example. Or, we can supose that we are using an activation function that returns the input. We call such a function the identity function.\n",
    "\n",
    "Let's say that the **true value of the target** is 3. So, the closer our prediction is to 3, the more accurate the model is for this data point.\n",
    "\n",
    "We will use **forward propagation** to fill in the values of the hidden layer.\n",
    "\n",
    "The **error** can be computes as follows: $$ \\text{Error} = \\text{Predicted target value} - \\text{Actual target value}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_network(input_data_point: np.ndarray, weights: Dict[str, List[int]]) -> np.float64:\n",
    "    node_0_input = (input_data_point * weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    node_1_input = (input_data_point * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    hidden_layer_values = np.array([node_0_output, node_1_output])\n",
    "    input_to_final_layer = (hidden_layer_values * weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "    \n",
    "    return(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "input_data: np.ndarray = np.array([0, 3])\n",
    "\n",
    "# Sample weights\n",
    "weights_0: Dict[str, List[int]] = {'node_0': [2, 1],\n",
    "                                   'node_1': [1, 2],\n",
    "                                   'output': [1, 1]}\n",
    "\n",
    "# The actual target value, use to calculate the error\n",
    "target_actual: int = 3\n",
    "\n",
    "# Make prediction using original weights\n",
    "model_output_0: List[np.float64] = predict_with_network(input_data, weights_0)\n",
    "\n",
    "# Calculate error\n",
    "error_0 = model_output_0 - target_actual\n",
    "\n",
    "# Create weights that cause the network to make perfect prediction (3)\n",
    "weights_1 = {'node_0': [2, 1],\n",
    "             'node_1': [1, 0],\n",
    "             'output': [1, 1]}\n",
    "\n",
    "# Make prediction using new weights\n",
    "model_output_1: List[np.float64] = predict_with_network(input_data, weights_1)\n",
    "\n",
    "# Calculate the new error\n",
    "error_1: np.int32 = model_output_1 - target_actual\n",
    "\n",
    "print(error_0)\n",
    "print(error_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 5.2 Scaling up to multiple data points\n",
    "\n",
    "We've seen how different weights will have different accuracies on a single prediction. But usually, we'll want to measure model accuracy on many points. \n",
    "\n",
    "We'll compare model accuracies for two different sets of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_0: Dict[str, np.ndarray] = {'node_0': np.array([2, 1]), \n",
    "                                    'node_1': np.array([1, 2]), \n",
    "                                    'output': np.array([1, 1])}\n",
    "\n",
    "weights_1: Dict[str, np.ndarray] = {'node_0': np.array([2, 1]),\n",
    "                                    'node_1': np.array([1. , 1.5]),\n",
    "                                    'output': np.array([1. , 1.5])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`input_data` is a list of arrays. Each item in that list contains the data to make a single prediction. \n",
    "\n",
    "`target_actuals` is a list of numbers. Each item in that list is the actual value we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data: List[np.ndarray] = [np.array([0, 3]), \n",
    "                                np.array([1, 2]), \n",
    "                                np.array([-1, -2]), \n",
    "                                np.array([4, 0])]\n",
    "\n",
    "target_actuals: List[int] =  [1, 3, 5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `mean_squared_error()` function from `sklearn.metrics`. It takes the true values and the predicted values as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error with weights_0: 37.50\n",
      "Mean squared error with weights_1: 49.89\n"
     ]
    }
   ],
   "source": [
    "model_output_0: List[np.int32] = []\n",
    "model_output_1: List[np.int32] = []\n",
    "\n",
    "for row in input_data:\n",
    "    model_output_0.append(predict_with_network(row, weights_0))\n",
    "    model_output_1.append(predict_with_network(row, weights_1))\n",
    "\n",
    "mse_0: float = mean_squared_error(target_actuals, model_output_0)\n",
    "mse_1: float = mean_squared_error(target_actuals, model_output_1)\n",
    "\n",
    "print(f\"Mean squared error with weights_0: {mse_0:.2f}\")\n",
    "print(f\"Mean squared error with weights_1: {mse_1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like `model_output_1` has a higher mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6. Gradient descent\n",
    "\n",
    "With gradient descent we repeatedly find a slope capturing how our loss function, $\\text{Loss}(\\omega)$, changes as a weight changes. We then do a small change to the weight to get to a lower point, and we repeat this process until we couldn't go downhill anymore.\n",
    "\n",
    "If the slope is positive, going opposite to the slope means moving to lower numbers. How do we achieve this? Subtracting the slope from the current value. But a too big step might lead us astray. Thus, instead of directly subtracting the slope, we multiply the slope by a small number, called the **learning rate**, and we update the weight by the product of that multiplication: $$ \\text{Updated weights} = \\text{weights} - \\text{slope} \\times \\text{learning rate}. $$\n",
    "\n",
    "We typically use a learning rate of $0.01$. This ensures that we take small steps, such that we reliably move towards the optimal weights.\n",
    "\n",
    "How do we find the relevant slope for each weight we need to update? Remember the chain rule of calculus... To calculate the slope for a weight, we need to multiply:\n",
    "1. The slope of the loss function wrt the value at the node we feed\n",
    "1. The value of the node that feeds into our weight\n",
    "1. The slope of the activation function wrt the value we feed into\n",
    "\n",
    "Let's put away the last point for a moment. The slope of the Mean-Squared loss function wrt to the prediction can be written as follows: $$2\\times\\text{Error}$$ where $\\text{error} = \\text{Predicted value} - \\text{Actual value}$ as aforementioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(input_data: np.ndarray, target: int, weights: np.ndarray) -> np.int32:\n",
    "    preds: np.int32 = (weights * input_data).sum()\n",
    "    error: np.int32 = preds - target\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(input_data: np.ndarray, target: int, weights: np.ndarray) -> np.ndarray:\n",
    "    error: np.int32 = get_error(input_data, target, weights)\n",
    "    slope: np.ndarray = 2 * input_data * error\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(input_data: np.ndarray, target: int, weights: np.ndarray) -> np.float64:\n",
    "    errors: np.int32 = get_error(input_data, target, weights)\n",
    "    mse: np.float64 = np.mean(errors**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data: np.ndarray = np.array([1, 2, 3])\n",
    "target: int = 0\n",
    "weights: np.ndarray = np.array([0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_updates: int = 20\n",
    "learning_rate: float = 0.01\n",
    "mse_hist: List[np.float64] = []\n",
    "\n",
    "# Iterate over the number of updates\n",
    "for i in range(n_updates):\n",
    "    # Calculate the slope\n",
    "    slope: np.ndarray = get_slope(input_data, target, weights)\n",
    "\n",
    "    # Update the weights\n",
    "    weights: np.ndarray = weights - slope * learning_rate\n",
    "\n",
    "    # Calculate MSE with new weights\n",
    "    mse: np.float64 = get_mse(input_data, target, weights)\n",
    "    mse_hist.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_hist, c='b', lw=1)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.grid(True, c='k', ls=':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we can see, the mean-squared error decreases as the number of iterations goes up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Creating a keras model\n",
    "\n",
    "The Keras workflow has 4 steps:\n",
    "1. Specify the architecture\n",
    "    1. How many layers?\n",
    "    1. How many nodes in each layer?\n",
    "    1. What activation function to use in each layer?\n",
    "1. Compile the model\n",
    "    * This specifies the loss function, and\n",
    "    * The optimization solver to use\n",
    "1. Fit the model\n",
    "1. Make predictions\n",
    "\n",
    "\n",
    "### Subsection 7.1: EDA\n",
    "We will soon start building models in Keras to predict wages based on various professional and demographic factors. Before we start building a model, it's good to understand our data by performing some exploratory analysis (EDA).\n",
    "\n",
    "The target variable we'll be predicting is `wage_per_hour`. Some of the predictor variables are binary indicators, where a value of `1` represents `True`, and `0` represents `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/hourly_wages.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 9 predictor variables in the DataFrame, how many are binary indicators? The `min` and `max` values as shown by `.describe()` will be informative here. So, how many binary indicator predictors are there? We can observe that there are 6 binary predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>534.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>44.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wage_per_hour  union  education_yrs  experience_yrs    age  female  \\\n",
       "count          534.0  534.0          534.0           534.0  534.0   534.0   \n",
       "mean             9.0    0.2           13.0            17.8   36.8     0.5   \n",
       "std              5.1    0.4            2.6            12.4   11.7     0.5   \n",
       "min              1.0    0.0            2.0             0.0   18.0     0.0   \n",
       "25%              5.2    0.0           12.0             8.0   28.0     0.0   \n",
       "50%              7.8    0.0           12.0            15.0   35.0     0.0   \n",
       "75%             11.2    0.0           15.0            26.0   44.0     1.0   \n",
       "max             44.5    1.0           18.0            55.0   64.0     1.0   \n",
       "\n",
       "        marr  south  manufacturing  construction  \n",
       "count  534.0  534.0          534.0         534.0  \n",
       "mean     0.7    0.3            0.2           0.0  \n",
       "std      0.5    0.5            0.4           0.2  \n",
       "min      0.0    0.0            0.0           0.0  \n",
       "25%      0.0    0.0            0.0           0.0  \n",
       "50%      1.0    0.0            0.0           0.0  \n",
       "75%      1.0    1.0            0.0           0.0  \n",
       "max      1.0    1.0            1.0           1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 534 entries, 0 to 533\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   wage_per_hour   534 non-null    float64\n",
      " 1   union           534 non-null    int64  \n",
      " 2   education_yrs   534 non-null    int64  \n",
      " 3   experience_yrs  534 non-null    int64  \n",
      " 4   age             534 non-null    int64  \n",
      " 5   female          534 non-null    int64  \n",
      " 6   marr            534 non-null    int64  \n",
      " 7   south           534 non-null    int64  \n",
      " 8   manufacturing   534 non-null    int64  \n",
      " 9   construction    534 non-null    int64  \n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 41.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 7.2: Specifying our model\n",
    "\n",
    "Now we'll get to work with our first model in Keras, and will immediately be able to run more complex neural network models on larger datasets.\n",
    "\n",
    "To start, we'll take the skeleton of a neural network and add a hidden layer and an output layer. We'll then fit that model and see Keras do the optimization so our model continually gets better.\n",
    "\n",
    "As a start, we'll predict workers wages based on characteristics like their industry, education and level of experience. For convenience, everything in `data` except for the target has been converted to a NumPy matrix called `predictors`. The target, `wage_per_hour`, is assigned to a NumPy matrix called `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\YBant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "predictors: ndarray = data.drop('wage_per_hour', axis=1).to_numpy()\n",
    "target: ndarray = data.wage_per_hour.to_numpy()\n",
    "    \n",
    "n_cols: int = predictors.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 7.3: Compiling and fitting our model\n",
    "\n",
    "Now that we've specified the model, the next step is to compile it, which sets up the network for optimization. For instance, creating an internal function to do back-propagation efficiently.\n",
    "\n",
    "The compile method has 2 important arguments for us to choose:\n",
    "1. What optimizer to use (which controls the learning rate)?\n",
    "    * In practice, the right choice of learning rate can make a huge difference for how quickly our model finds good weights, and even how good a set of weights it can find.\n",
    "    * There are a few algorithms that automatically tune the learning rate. Even many experts in the field don't know all the details of all the optimization algorithms. Therefore, the pragmatic approach is to choose a versatile algorithm and use that for most problems. In that sense, \"Adam\" is an excellent choice as out go-to optimizer. \"Adam\" adjusts the learning rate as it does gradient descent to ensure reasonable values throughout the weight optimization process.\n",
    "1. What loss function to use?\n",
    "    * `'mean_squared_error'` is the most common choice for regression problems. However, when we use keras for classification, we will use a new default metric.\n",
    "    \n",
    "You can read more about the Adam optimizer as well as other keras optimizers [here](https://keras.io/api/optimizers/#adam), and if you are really curious to learn more, you can read the [original paper](https://arxiv.org/abs/1412.6980v8) that introduced the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: 'mean_squared_error'\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "print(f'Loss function: {model.loss!r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have compiled our model, we can fit it. That is, applying back-propagation and gradient descent with our data to update the weights.\n",
    "\n",
    "The fit step looks similar to the scikit-learn's one, though it has more options which we will explore soon.\n",
    "\n",
    "Even with the \"Adam\" optimizer, wich is pretty smart, it can improve our optimization process if we scale all the data such that each feature is, on average, about similar sized values. One common approach is to subtract each feature by that feature's mean, and divide it by it's standard deviation. This process is called normalization: $$ z = \\frac{x -\\mu}{\\sigma} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\YBant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "534/534 [==============================] - 0s 387us/step - loss: 44.5897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2489ff3c6a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8. Classification models\n",
    "\n",
    "For classification, we do a couple of things differently.\n",
    "\n",
    "The biggest changes are:\n",
    "1. Set the loss function as `'categorical_crossentropy'` instead of `'mean_squared_error'`. This isn't the only possible loss function for classification problems, but it is by far the most common. For a **categorical crossentropy loss function**, a **lower score is better**. But it is still hard to interpret. Therefore, we can add `metrics = ['accuracy']` to the compile sten for easy-to-understand diagnostics.\n",
    "1. Modify the last layer such that is has a separate note for each potential outcome. We also change the activation function to `'softmax'`. The softmax activation function ensures the predictions sum to 1 such that they can be interpreted like probabilities.\n",
    "\n",
    "Now we will start modeling with a new dataset for a classification problem. This data includes information about passengers on the Titanic. We will use predictors such as `age`, `fare` and where each passenger embarked from to predict who will survive. This data is from a [kaggle tutorial](https://www.kaggle.com/c/titanic). Look [here](https://www.kaggle.com/c/titanic/data) for descriptions of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male  age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1            False   \n",
       "1         1       1  38.0      1      0  71.2833     0            False   \n",
       "2         1       3  26.0      0      0   7.9250     0            False   \n",
       "3         1       1  35.0      1      0  53.1000     0            False   \n",
       "4         0       3  35.0      0      0   8.0500     1            False   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_filepath: str = normabspath(basedir, 'data/titanic_all_numeric.csv')\n",
    "titanic: DataFrame = pd.read_csv(titanic_filepath)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   survived                   891 non-null    int64  \n",
      " 1   pclass                     891 non-null    int64  \n",
      " 2   age                        891 non-null    float64\n",
      " 3   sibsp                      891 non-null    int64  \n",
      " 4   parch                      891 non-null    int64  \n",
      " 5   fare                       891 non-null    float64\n",
      " 6   male                       891 non-null    int64  \n",
      " 7   age_was_missing            891 non-null    bool   \n",
      " 8   embarked_from_cherbourg    891 non-null    int64  \n",
      " 9   embarked_from_queenstown   891 non-null    int64  \n",
      " 10  embarked_from_southampton  891 non-null    int64  \n",
      "dtypes: bool(1), float64(2), int64(8)\n",
      "memory usage: 70.6 KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's smart to review the maximum and minimum values of each variable to ensure the data isn't misformatted or corrupted. What was the maximum age of passengers on the Titanic? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>32.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>49.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>512.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       survived  pclass    age  sibsp  parch   fare   male  \\\n",
       "count     891.0   891.0  891.0  891.0  891.0  891.0  891.0   \n",
       "mean        0.4     2.3   29.7    0.5    0.4   32.2    0.6   \n",
       "std         0.5     0.8   13.0    1.1    0.8   49.7    0.5   \n",
       "min         0.0     1.0    0.4    0.0    0.0    0.0    0.0   \n",
       "25%         0.0     2.0   22.0    0.0    0.0    7.9    0.0   \n",
       "50%         0.0     3.0   29.7    0.0    0.0   14.5    1.0   \n",
       "75%         1.0     3.0   35.0    1.0    0.0   31.0    1.0   \n",
       "max         1.0     3.0   80.0    8.0    6.0  512.3    1.0   \n",
       "\n",
       "       embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "count                    891.0                     891.0   \n",
       "mean                       0.2                       0.1   \n",
       "std                        0.4                       0.3   \n",
       "min                        0.0                       0.0   \n",
       "25%                        0.0                       0.0   \n",
       "50%                        0.0                       0.0   \n",
       "75%                        0.0                       0.0   \n",
       "max                        1.0                       1.0   \n",
       "\n",
       "       embarked_from_southampton  \n",
       "count                      891.0  \n",
       "mean                         0.7  \n",
       "std                          0.4  \n",
       "min                          0.0  \n",
       "25%                          0.0  \n",
       "50%                          1.0  \n",
       "75%                          1.0  \n",
       "max                          1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 152us/step - loss: 3.0627 - acc: 0.6263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2489eea3208>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target: ndarray = to_categorical(titanic.survived)\n",
    "predictors: ndarray = titanic.drop('survived', axis=1).to_numpy()\n",
    "n_cols: int = predictors.shape[1]\n",
    "    \n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols, )))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple model is generating an accuracy greater than 60%!\n",
    "\n",
    "## Section 9. Using models\n",
    "\n",
    "The usual workflow associated with deep learning models is:\n",
    "1. Save the model after you have trained it\n",
    "1. Reload the model\n",
    "1. Make prediction with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 418\n",
      "Trainable params: 418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_filepath: str = normabspath(basedir, 'models/classification_model.h5')\n",
    "    \n",
    "# Save the model\n",
    "model.save(model_filepath)\n",
    "\n",
    "# Load the model back into memory\n",
    "my_model: Sequential = load_model(model_filepath)\n",
    "\n",
    "# Make predictions (they come in the same format as the prediction target, here 2 columns)\n",
    "predictions: ndarray = my_model.predict(predictors)\n",
    "    \n",
    "# Individuals who would survive on the Titanic\n",
    "probability_true = predictions[:, 1]\n",
    "\n",
    "# Summary of the model architecture\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10. Understanding model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to get our hands dirty with optimization. We'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. We'll want to look at the output after running the code, remembering that a low value for the loss function is good.\n",
    "\n",
    "We will use the predictors and target from section 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_model(input_shape: Tuple[Union[None, int], Union[None, int]]) -> Sequential:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 1e-06\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 221us/step - loss: 2.4079\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.01\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 311us/step - loss: 8.3163\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 327us/step - loss: 6.0273\n"
     ]
    }
   ],
   "source": [
    "learning_rates_to_test: Tuple[int, int, int] = (.000001, .01, 1)\n",
    "\n",
    "for lr in learning_rates_to_test:\n",
    "    print(f\"\\n\\nTesting model with learning rate: {lr}\")\n",
    "    model = get_new_model(input_shape=(n_cols, ))\n",
    "    sgd = SGD(lr=lr)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "    model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, the lowest value for the loss function (categorical crossentropy) is achieved by the middle learning rate 0.01. Worst case is achieved utilizing a learning rate equal to 1.\n",
    "\n",
    "## Section 11. Model Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras243py37",
   "language": "python",
   "name": "keras243py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
